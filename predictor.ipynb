{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8793ee-f04b-4390-b839-c980097ee020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e07a2-8dca-4e25-b201-aae2f346b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Machine learning detection model\n",
    "predictor = Predictor(config)\n",
    "os.makedirs('data/predictor', exist_ok=True)\n",
    "shutil.copyfile(os.path.join('data', 'slides', '4x', acq_name_4x+'.ome.tif'), os.path.join('data/predictor', acq_name_4x+'.ome.tif'))\n",
    "subprocess.run([\"python\", \"patch_extraction.py\", \"-s\", config[\"slide-type\"], \"-f\", \"tif\", \"-p\", \"1\"], shell=True)\n",
    "slides = glob.glob(os.path.join('data-predictor', '*.tif')) + glob.glob(os.path.join('data-predictor', '*.jpg'))\n",
    "pos = []\n",
    "image_format = slides[0].split('.')[-1]\n",
    "for slide in slides:\n",
    "    slide_name = slide.split(os.sep)[-1].replace('.'+image_format, '')\n",
    "    fields = glob.glob(os.path.join('data-predictor', slide_name, '*.tif'))\n",
    "    if config[\"classifier\"] == \"Supervised\":\n",
    "        for field in fields:\n",
    "            pos_x = int(field.split('x=')[1].split(',')[0])\n",
    "            pos_y = int(field.split('y=')[1].split(',')[0])\n",
    "            img = io.imread(field)\n",
    "            prediction = predictor.compute(img)\n",
    "            c = np.argmax(prediction)\n",
    "            pos.append([int(pos_x/224), int(pos_y/224), c])\n",
    "    if config[\"classifier\"] == \"MIL\":\n",
    "        prediction_bag, prediction_patch = predictor.compute(fields)\n",
    "        if prediction_bag:\n",
    "            for i in range(len(fields)):\n",
    "                pos_x = int(fields[i].split('x=')[1].split(',')[0])\n",
    "                pos_y = int(fields[i].split('y=')[1].split(',')[0])\n",
    "                pos.append([int(pos_x/224), int(pos_y/224), prediction_patch[i]])\n",
    "pos_arr = np.vstack(pos)\n",
    "w = np.max(pos_arr, 0)[0]+1\n",
    "h = np.max(pos_arr, 0)[1]+1\n",
    "cmap = np.zeros((h ,w))\n",
    "for p in pos:\n",
    "    cmap[p[1], p[0]] = p[2]\n",
    "if config[\"slide-type\"] == \"slide\":\n",
    "    cmap_p = morphology.remove_small_objects(img_as_bool(cmap), min_size=6)\n",
    "    cmap_p = morphology.remove_small_holes(cmap_p, area_threshold=8)\n",
    "if config[\"slide-type\"] == \"TMA\":\n",
    "    cmap_p = cmap\n",
    "plt.imshow(cmap_p)\n",
    "os.makedirs(os.path.join('qupath-projects', 'predictions'), exist_ok=True)\n",
    "io.imsave(os.path.join('qupath-projects', 'predictions', slide_name+'-cmap.bmp'), img_as_ubyte(cmap_p))\n",
    "# resample 20x bf\n",
    "field_4x = 224 * config[\"pixel-size-bf-4x\"]\n",
    "field_w_20x = config[\"camera-resolution\"][0] * config[\"pixel-size-bf-20x\"] * 0.9\n",
    "field_h_20x = config[\"camera-resolution\"][1] * config[\"pixel-size-bf-20x\"] * 0.9\n",
    "rw = int(w * (field_4x/field_w_20x))\n",
    "rh = int(h * (field_4x/field_h_20x))\n",
    "cmap_r = transform.resize(cmap_p, (rh, rw), order=1, mode='symmetric')\n",
    "thresh = threshold_mean(cmap_r)*0.5\n",
    "cmap_r = cmap_r >= thresh\n",
    "ps_pos = np.where(cmap_r==1)\n",
    "pos_20x_df = pd.DataFrame({\n",
    "    'x_pos' : ps_pos[1]*field_w_20x/config[\"pixel-size-bf-4x\"],\n",
    "    'y_pos' : ps_pos[0]*field_h_20x/config[\"pixel-size-bf-4x\"]}\n",
    ")\n",
    "# resample shg\n",
    "field_mp = 256 * config[\"pixel-size-shg-base\"] * 0.9\n",
    "rw = int(w * (field_4x/field_mp))\n",
    "rh = int(h * (field_4x/field_mp))\n",
    "cmap_r = transform.resize(cmap_p, (rh, rw), order=1, mode='symmetric')\n",
    "thresh = threshold_mean(cmap_r)*0.5\n",
    "cmap_r = cmap_r >= thresh\n",
    "ps_pos = np.where(cmap_r==1)\n",
    "pos_mp_df = pd.DataFrame({default_bg_20x\n",
    "    'x_pos' : ps_pos[1]*field_mp/config[\"pixel-size-bf-4x\"],\n",
    "    'y_pos' : ps_pos[0]*field_mp/config[\"pixel-size-bf-4x\"]}\n",
    ")\n",
    "if image_format == 'tif':\n",
    "    pos_mp_df.to_csv(os.path.join('qupath-projects', 'predictions', 'mp-'+slide_name+'.tif.csv'), index=False)\n",
    "    pos_mp_df.to_csv(os.path.join('qupath-projects', 'mp-tiles', slide_name+'.tif.csv'), index=False)\n",
    "    pos_20x_df.to_csv(os.path.join('qupath-projects', 'predictions', '20x-'+slide_name+'.tif.csv'), index=False)\n",
    "    pos_20x_df.to_csv(os.path.join('qupath-projects', '20x-tiles', slide_name+'.tif.csv'), index=False)\n",
    "if image_format == 'jpg':\n",
    "    pos_mp_df.to_csv(os.path.join('qupath-projects', 'predictions', 'mp-'+slide_name+'.csv'), index=False)\n",
    "    pos_mp_df.to_csv(os.path.join('qupath-projects', 'mp-tiles', slide_name+'.csv'), index=False)\n",
    "    pos_20x_df.to_csv(os.path.join('qupath-projects', 'predictions', '20x-'+slide_name+'.csv'), index=False)\n",
    "    pos_20x_df.to_csv(os.path.join('qupath-projects', '20x-tiles', slide_name+'.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
