{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmartPath: Intelligent Multimodal Acquisition for Histopathological Whole Slide Scanning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Instructions:  \n",
    "How to run a cell (section)?\n",
    "Click blank space in front of the '...' below each section and hit Shift+Return, or click the \"run the selected cells and advance\" botton in the top menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System configuration\n",
    "Note: wait for \"System configured!\" Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System configured!\n"
     ]
    }
   ],
   "source": [
    "import os, glob, shutil, sys, copy, time, json, copy, subprocess\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "from pycromanager import Acquisition, Bridge, Dataset, multi_d_acquisition_events\n",
    "from skimage import io, img_as_ubyte, img_as_float, img_as_uint, color, transform, exposure\n",
    "from skimage.filters import threshold_mean, sobel\n",
    "from skimage.measure import shannon_entropy\n",
    "from skimage.util import view_as_windows, crop\n",
    "import imagej\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.stats import norm\n",
    "import scipy as sp\n",
    "from shapely.geometry import mapping, shape\n",
    "from tkinter import filedialog\n",
    "import warnings\n",
    "\n",
    "from acquisitions import *\n",
    "from image_utils import *\n",
    "from enhancer import Enhancer\n",
    "\n",
    "os.environ['_JAVA_OPTIONS']=\"-Xmx12g\"\n",
    "warnings.filterwarnings('ignore')\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def config_sys(config):\n",
    "    if config[\"exposure-level\"]==\"low\":\n",
    "        config[\"lsm-scan-rate\"] = '500000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.3\n",
    "        config[\"lsm-pmt-gain\"] = 0.35\n",
    "    if config[\"exposure-level\"]==\"mid\":\n",
    "        config[\"lsm-scan-rate\"] = '400000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.4\n",
    "        config[\"lsm-pmt-gain\"] = 0.4\n",
    "    if config[\"exposure-level\"]==\"high\":\n",
    "        config[\"lsm-scan-rate\"] = '250000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.425\n",
    "        config[\"lsm-pmt-gain\"] = 0.425\n",
    "    if config[\"exposure-level\"]==\"extreme\":\n",
    "        config[\"lsm-scan-rate\"] = '200000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.45\n",
    "        config[\"lsm-pmt-gain\"] = 0.45\n",
    "    config[\"pixel-size-shg\"] = config[\"pixel-size-shg-base\"] * 256 / config[\"lsm-resolution\"]\n",
    "    if config[\"enhancement-type\"] is not None:\n",
    "        config[\"enhancer\"] = Enhancer(config)\n",
    "    return config\n",
    "\n",
    "def whole_slide_scan(config, core=None, save_path=None, acq_name=None, position_list=None, mag='4x', mda=False, z_stack=False, z_center=None, sample_depth=20, z_step=4, estimate_background=False, background_image=None, focus_dive=False):\n",
    "    if mda == True:\n",
    "        if position_list.shape[1] == 3:\n",
    "            if z_stack:\n",
    "                with Acquisition(save_path, acq_name, lsm_process_fn(config)) as acq:\n",
    "                    events = multi_d_acquisition_events(xyz_positions=position_list.reshape(-1, 3), z_start=-int(sample_depth/2), z_end=int(sample_depth/2), z_step=z_step)\n",
    "                    acq.acquire(events)      \n",
    "            else:\n",
    "                with Acquisition(save_path, acq_name) as acq:\n",
    "                    events = multi_d_acquisition_events(xyz_positions=position_list.reshape(-1, 3))\n",
    "                    acq.acquire(events)\n",
    "        else:\n",
    "            if z_center is None:\n",
    "                z_center = config[\"Z-stage-laser\"]\n",
    "            if z_stack:\n",
    "                with Acquisition(save_path, acq_name) as acq:\n",
    "                    events = multi_d_acquisition_events(xy_positions=position_list.reshape(-1, 2), z_start=-int(sample_depth/2) + z_center, z_end=int(sample_depth/2) + z_center, z_step=z_step)\n",
    "                    acq.acquire(events)\n",
    "            else:\n",
    "                with Acquisition(save_path, acq_name) as acq:\n",
    "                    events = multi_d_acquisition_events(xy_positions=position_list.reshape(-1, 2))\n",
    "                    acq.acquire(events)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        plt.axis(\"off\")\n",
    "        show = plt.imshow(np.zeros((config[\"camera-resolution\"][1], config[\"camera-resolution\"][0])))\n",
    "        acq_id = len(glob.glob(os.path.join(save_path, acq_name+\"*\")))\n",
    "        acq_path = os.path.join(save_path, acq_name+\"_{}\".format(acq_id+1))\n",
    "        os.makedirs(acq_path, exist_ok=True)\n",
    "        redive_flag = True\n",
    "        bg_flag = False\n",
    "        if estimate_background:\n",
    "            sum_img = np.zeros((config[\"camera-resolution\"][1], config[\"camera-resolution\"][0], 3))\n",
    "            sum_count = 0\n",
    "        if background_image is not None:\n",
    "            bg_img = white_balance(copy.deepcopy(background_image), copy.deepcopy(background_image))\n",
    "        if position_list.shape[1] == 3:\n",
    "            tile_count = 0\n",
    "            z_positions=np.ones(position_list.shape[0]) * core.get_position()\n",
    "            core.set_focus_device(config[\"focus-device\"])                \n",
    "            for pos in range(position_list.shape[0]):\n",
    "                z_pos = position_list[pos, 2]\n",
    "                x_pos = position_list[pos, 0]\n",
    "                y_pos = position_list[pos, 1]\n",
    "                if (z_pos < config[\"hard-limit-z\"][0] or z_pos > config[\"hard-limit-z\"][1] \n",
    "                    or x_pos < config[\"hard-limit-x\"][0] or x_pos > config[\"hard-limit-x\"][1]\n",
    "                    or y_pos < config[\"hard-limit-y\"][0] or y_pos > config[\"hard-limit-y\"])[1]:\n",
    "                    print('position out of range')\n",
    "                    break\n",
    "                core.set_position(z_pos)\n",
    "                core.set_xy_position(x_pos, y_pos)\n",
    "                xy_device = core.get_xy_stage_device()\n",
    "                z_device = core.get_focus_device()\n",
    "                core.wait_for_device(xy_device)\n",
    "                core.wait_for_device(z_device)\n",
    "                if focus_dive and mag=='4x':\n",
    "                    if redive_flag:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=1000, steps=5, snap=False)\n",
    "                        if not bg_flag:\n",
    "                            pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=200, steps=5, snap=True)\n",
    "                    else:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=200, steps=5, snap=True)\n",
    "                    z_positions[pos] = pos_z\n",
    "                if focus_dive and mag=='20x':\n",
    "                    if True:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='20x', rgb=True, search_range=150, steps=5, check_background=True, snap=False)\n",
    "                        if not bg_flag:\n",
    "                            pos_z, _, _ = autofocus(config, core, mag='20x', rgb=True, search_range=25, steps=5, check_background=False, snap=False)\n",
    "                            pos_z, pixels, _ = autofocus(config, core, mag='20x', rgb=True, search_range=5, steps=5, check_background=False, snap=True)\n",
    "                    z_positions[pos] = pos_z\n",
    "                else:\n",
    "                    pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                pixels = img_as_float(pixels)\n",
    "                if estimate_background:\n",
    "                    if focus_dive:\n",
    "                        bg_flag = bg_flag\n",
    "                    else:\n",
    "                        bg_flag = is_background(pixels)\n",
    "                    if bg_flag:\n",
    "                        print(' (background tile)')\n",
    "                        redive_flag=True\n",
    "                        sum_img = sum_img + pixels\n",
    "                        sum_count = sum_count + 1\n",
    "                    else:\n",
    "                        redive_flag=False  \n",
    "                if background_image is not None:\n",
    "                    pixels = white_balance(pixels, background_image)\n",
    "                    pixels = flat_field(pixels, bg_img)\n",
    "                show.set_data(pixels)\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "                io.imsave(acq_path+'/{}.tiff'.format(pos), img_as_ubyte(pixels))\n",
    "                tile_count = tile_count + 1\n",
    "                sys.stdout.write('\\r {}/{} tiles done'.format(tile_count, position_list.shape[0]))\n",
    "                    \n",
    "        if position_list.shape[1] == 2:\n",
    "            tile_count = 0\n",
    "            core.set_focus_device(config[\"focus-device\"])\n",
    "            z_positions=np.ones(position_list.shape[0]) * core.get_position()\n",
    "            for pos in range(position_list.shape[0]):\n",
    "                x_pos = position_list[pos, 0]\n",
    "                y_pos = position_list[pos, 1]\n",
    "                if ( x_pos < config[\"hard-limit-x\"][0] or x_pos > config[\"hard-limit-x\"][1]\n",
    "                    or y_pos < config[\"hard-limit-y\"][0] or y_pos > config[\"hard-limit-y\"][1]):\n",
    "                    print('position out of range')\n",
    "                    break\n",
    "                core.set_xy_position(x_pos, y_pos)\n",
    "                xy_device = core.get_xy_stage_device()\n",
    "                core.wait_for_device(xy_device)\n",
    "                if focus_dive and mag=='4x':\n",
    "                    if redive_flag:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=1000, steps=5, snap=False)\n",
    "                        if not bg_flag:\n",
    "                            pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=250, steps=5, snap=True)\n",
    "                    else:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=500, steps=5, snap=True)\n",
    "                    z_positions[pos] = pos_z\n",
    "                if focus_dive and mag=='20x':\n",
    "                    if True:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='20x', rgb=True, search_range=150, steps=5, check_background=True, snap=False)\n",
    "                        if not bg_flag:\n",
    "                            pos_z, _, _ = autofocus(config, core, mag='20x', rgb=True, search_range=25, steps=5, check_background=False, snap=False)\n",
    "                            pos_z, pixels, _ = autofocus(config, core, mag='20x', rgb=True, search_range=5, steps=5, check_background=False, snap=True)\n",
    "                    z_positions[pos] = pos_z\n",
    "                else:\n",
    "                    pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                pixels = img_as_float(pixels)\n",
    "                if estimate_background:\n",
    "                    if focus_dive:\n",
    "                        bg_flag = bg_flag\n",
    "                    else:\n",
    "                        bg_flag = is_background(pixels)\n",
    "                    if bg_flag:\n",
    "                        print(' (background tile)')\n",
    "                        redive_flag=True\n",
    "                        sum_img = sum_img + pixels\n",
    "                        sum_count = sum_count + 1\n",
    "                    else:\n",
    "                        redive_flag=False                \n",
    "                if background_image is not None:\n",
    "                    pixels = white_balance(config, pixels, background_image)\n",
    "                    pixels = flat_field(pixels, bg_img)\n",
    "                show.set_data(pixels)\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "                io.imsave(acq_path+'/{}.tiff'.format(pos), img_as_ubyte(pixels))\n",
    "                tile_count = tile_count + 1\n",
    "                sys.stdout.write('\\r {}/{} tiles done'.format(tile_count, position_list.shape[0]))\n",
    "        returns = []\n",
    "        if estimate_background:\n",
    "            returns.append((sum_img / sum_count))\n",
    "            io.imsave(acq_path+'/bg_img.tiff', img_as_ubyte(np.squeeze(sum_img / sum_count)))\n",
    "        if focus_dive:\n",
    "            z_positions = z_positions.reshape(position_list.shape[0], 1)\n",
    "            returns.append(z_positions)\n",
    "        return tuple(returns)\n",
    "\n",
    "def autofocus(config, core, method='edge', mag='4x', rgb=True, search_range=45, steps=5, snap=True, crop_ratio=1.0, flip_channel=True, check_background=True, offset=0):\n",
    "    if mag=='4x':\n",
    "        drift_limit = config[\"Z-stage-4x\"]\n",
    "    if mag=='20x':\n",
    "        drift_limit = config[\"Z-stage-20x\"]\n",
    "    core.set_focus_device(config[\"focus-device\"])   \n",
    "    current_z = core.get_position()\n",
    "    interval_z = search_range/steps\n",
    "    scores = []\n",
    "    positions = []\n",
    "    count = 0\n",
    "    for step in range(-int(np.floor(steps/2)), int(np.ceil(steps/2))):\n",
    "        position_z = step * interval_z + current_z\n",
    "        if position_z < config[\"hard-limit-z\"][0] or position_z > config[\"hard-limit-z\"][1]:\n",
    "            print(\"z-stage out of range, new focus discarded\")\n",
    "            break\n",
    "        core.set_position(position_z)\n",
    "        core.wait_for_system()\n",
    "        count = count + 1\n",
    "        pixels = snap_image(core, rgb=rgb, flip_channel=True)\n",
    "        if check_background and step==-int(np.floor(steps/2)):\n",
    "            bg_flag = is_background(pixels)\n",
    "            if bg_flag:\n",
    "                core.set_position(current_z)\n",
    "                core.wait_for_system()\n",
    "                print(\"Is background\")\n",
    "                return current_z, pixels, bg_flag\n",
    "        img_gray = color.rgb2gray(pixels)\n",
    "        print(\"\\n Diving focus at \" + str(step))\n",
    "        if method == 'entropy':\n",
    "            score = shannon_entropy(img_gray)\n",
    "        if method == 'edge':\n",
    "            score = np.mean(sobel(img_gray))\n",
    "        scores.append(score)\n",
    "        positions.append(position_z)\n",
    "    scores_array = np.asarray(scores)\n",
    "    positions_array = np.asarray(positions) \n",
    "    new_length = len(positions) * 100\n",
    "    new_x = np.linspace(positions_array.min(), positions_array.max(), new_length)\n",
    "    new_y = sp.interpolate.interp1d(positions_array, scores_array, kind='cubic')(new_x)\n",
    "    idx = np.argmax(new_y)\n",
    "    focus_z = new_x[idx]\n",
    "    if focus_z < config[\"hard-limit-z\"][0] or focus_z > config[\"hard-limit-z\"][1]:\n",
    "        print(\"z-stage out of range, new focus discarded\")\n",
    "        focus_z = position_z\n",
    "    if np.abs(focus_z-drift_limit) > 1000:\n",
    "        print(\"z-stage out of range, reset focus\")\n",
    "        focus_z = drift_limit\n",
    "        core.set_position(drift_limit)\n",
    "        core.wait_for_system()\n",
    "    else:\n",
    "        core.set_position(focus_z)\n",
    "        core.wait_for_system()\n",
    "    if snap:\n",
    "        pixels = snap_image(core, rgb=rgb, flip_channel=True)\n",
    "        return focus_z+offset, pixels, False\n",
    "    else:\n",
    "        return focus_z+offset, None, False    \n",
    "\n",
    "print(\"System configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acquisition hardware configuration\n",
    "Edit user configuration. After editing, click blank space in front of the section and hit Shift+Return, or click the \"run the selected cells and advance\" botton in the top menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_config = {\n",
    "    \n",
    "    ### User configuration ###\n",
    "    \n",
    "    # Quick configuration group for LSM\n",
    "    \"exposure-level\" : 'mid',\n",
    "    # 'low'     -> scan rate: '500000.0000', pockel cell gain: 0.3, PMT gain: 0.35\n",
    "    # 'mid'     -> scan rate: '400000.0000', pockel cell gain: 0.4, PMT gain: 0.4\n",
    "    # 'high'    -> scan rate: '250000.0000', pockel cell gain: 0.425, PMT gain: 0.425\n",
    "    # 'extreme' -> scan rate: '200000.0000', pockel cell gain: 0.45, PMT gain: 0.45\n",
    "    \n",
    "    \"snr-level\" : 'low',\n",
    "    # Estimiated correction according to sample SNR level. Available value: 'low', 'mid', 'high'\n",
    "       \n",
    "    \"lsm-resolution\" : 256, \n",
    "    # LSM scan resolution, available resolution: 256, 512, 1024\n",
    "    \n",
    "    \"lsm-bin-factor\" : 3,\n",
    "    # LSM scan pixel average factor, positive integer\n",
    "    \n",
    "    \"lsm-scan-rate\" : '400000.0000', \n",
    "    # LSM scan rate, available value (string): '125000.0000', '200000.0000', '250000.0000','400000.0000', '500000.0000', '625000.0000', '1000000.0000'\n",
    "    \n",
    "    \"lsm-pc-power\" : 0.4, \n",
    "    # LSM pockel cell gain, float point value: 0.0 ~ 1.0\n",
    "    \n",
    "    \"lsm-pmt-gain\" : 0.4,\n",
    "    # LSM PMT gain, float point value: 0.0 ~ 1.0\n",
    "    \n",
    "    \"slide-box\" : (0, -1000, 30000.0, 21000.0), \n",
    "    # Pre-define scan area (read out values from the stage): (start x stage position, start y stage position, end x stage position, end y stage position)\n",
    "    \n",
    "    \"enhancement-type\" : None,\n",
    "    # Runtime enhancement method, available value (string or boolean): 'Self', 'Supervised', None\n",
    "    \n",
    "    \"gpu\" : False,\n",
    "    # Is GPU available? Available value (boolean): True, False       \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate acquisition configuration\n",
    "Run the below section. Wait for message containing the configuration specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration specs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exposure-level': 'mid',\n",
       " 'snr-level': 'low',\n",
       " 'lsm-resolution': 256,\n",
       " 'lsm-bin-factor': 3,\n",
       " 'lsm-scan-rate': '400000.0000',\n",
       " 'lsm-pc-power': 0.4,\n",
       " 'lsm-pmt-gain': 0.4,\n",
       " 'slide-box': (0, -1000, 30000.0, 21000.0),\n",
       " 'enhancement-type': None,\n",
       " 'gpu': False,\n",
       " 'pixel-size-bf-20x': 0.222,\n",
       " 'pixel-size-bf-4x': 1.105,\n",
       " 'pixel-size-shg-base': 0.509,\n",
       " 'pixel-size-shg': 0.509,\n",
       " 'camera-resolution': (1392, 1040),\n",
       " 'lsm-resolution-base': (512, 512),\n",
       " 'slide-size': (35000.0, 20000.0),\n",
       " 'Z-stage-20x': -6930,\n",
       " 'Z-stage-laser': -6640,\n",
       " 'Z-stage-4x': 3570,\n",
       " 'F-stage-20x': -15000,\n",
       " 'F-stage-laser': -18500,\n",
       " 'F-stage-4x': -1000,\n",
       " 'hard-limit-z': (-7700.0, 17000.0),\n",
       " 'hard-limit-x': (-2000.0, 40000.0),\n",
       " 'hard-limit-y': (-2000, 24000.0),\n",
       " 'hard-limit-f': (-19000, 0),\n",
       " '20x-bf-offset': (-600, 10),\n",
       " 'shg-offset': (-580, -280),\n",
       " 'led-4x': 4,\n",
       " 'led-20x': 5,\n",
       " 'focus-device': 'ZStage:Z:32',\n",
       " 'condensor-device': 'ZStage:F:32',\n",
       " 'led-device': ('LED-Dev1ao0', 'Voltage'),\n",
       " 'obj-device': ('Turret:O:35', 'Label')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_config = {\n",
    "    ### Hard configuration, \n",
    "    \"pixel-size-bf-20x\" : 0.222, # 0.222 micron/pixel at (1392, 1040)\n",
    "    \"pixel-size-bf-4x\" : 1.105, # 1.305 micron/pixel at (1392, 1040)\n",
    "    \"pixel-size-shg-base\" : 0.509, # 0.509 micron/pixel at 256\n",
    "    \"pixel-size-shg\" : 0.509,\n",
    "    \"camera-resolution\" : (1392, 1040), # (width, height)\n",
    "    \"lsm-resolution-base\" : (512, 512),\n",
    "    \"slide-size\" : (35000.0, 20000.0), # (width, height) (70000, -20000)\n",
    "    \"Z-stage-20x\" : -6930, # -6930 + 290\n",
    "    \"Z-stage-laser\" : -6640, #-6640 \n",
    "    \"Z-stage-4x\" : 3570, # -2300\n",
    "    \"F-stage-20x\" : -15000, # 11000\n",
    "    \"F-stage-laser\" : -18500, # -17500\n",
    "    \"F-stage-4x\" : -1000,\n",
    "    \"hard-limit-z\" : (-7700.0, 17000.0),\n",
    "    \"hard-limit-x\" : (-2000.0, 40000.0),\n",
    "    \"hard-limit-y\" : (-2000, 24000.0),\n",
    "    \"hard-limit-f\" : (-19000, 0),\n",
    "    \"20x-bf-offset\" : (-600, 10), # 4x + this value to 20x // (-590, 74)\n",
    "    \"shg-offset\" : (-580, -280), # 4x + this value to shg // (-580, -172)\n",
    "    \"led-4x\" : 4,\n",
    "    \"led-20x\" : 5,\n",
    "    \"focus-device\" : 'ZStage:Z:32',\n",
    "    \"condensor-device\" : 'ZStage:F:32',\n",
    "    \"led-device\" : ('LED-Dev1ao0', 'Voltage'),\n",
    "    \"obj-device\" : ('Turret:O:35', 'Label'),\n",
    "}\n",
    "config = {**user_config, **hard_config}\n",
    "config = config_sys(config)\n",
    "print(\"Configuration specs:\")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Pycro-Manager and PyImageJ\n",
    "Make sure Micro-Manager and OpenScan is running appropriately. Run the below section. Wait for message \"Succeeded!\". Run only once, unless the notebook or Micro-Manager had restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded!\n"
     ]
    }
   ],
   "source": [
    "bridge = Bridge()\n",
    "core = bridge.get_core()\n",
    "studio = bridge.get_studio()\n",
    "ij = imagej.init('fiji\\\\fiji\\\\Fiji.app')\n",
    "core.set_timeout_ms(20000)\n",
    "print(\"Succeeded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure acquistion parameters\n",
    "Enter values and run the below section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = 'data/acquisition'\n",
    "# Data save path, relative path by default\n",
    "\n",
    "acq_name = 'HPan-Ade170Sur-101'\n",
    "# Acquisition name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Brighfield acquisition at 4x\n",
    "Run the below section. Wait for the \"4x brighfield acquisition done!\" message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4x acqusition\n",
    "position_list = generate_grid(config, mag='4x')\n",
    "acq_name_4x = acq_name + '-4x-bf'\n",
    "switch_objective(config, core, '4x')\n",
    "switch_mod(config, core, mod='bf')\n",
    "returns = whole_slide_scan(config, core=core, save_path=save_path, acq_name=acq_name_4x, position_list=position_list.reshape(position_list.shape[0]*position_list.shape[1], -1), mda=False, estimate_background=True, focus_dive=True)\n",
    "stitching(config, ij, save_path=save_path, acq_name=acq_name_4x, mda=False, position_list=position_list.reshape(position_list.shape[0]*position_list.shape[1], -1), flip_y=True, correction=True, background_image=returns[0])\n",
    "export_slide(mag='4x')\n",
    "pd_arr = pd.DataFrame(returns[1])\n",
    "pd_arr.to_csv(os.path.join(save_path, acq_name_4x+'-z_pos.csv'), index=False)\n",
    "pd_arr_r = pd.read_csv(os.path.join(save_path, acq_name_4x+'-z_pos.csv'))\n",
    "z_pos_4x = np.array(pd_arr_r)\n",
    "print('\\r, 4x brighfield acquisition done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Brighfield acquisition at 20x\n",
    "Make sure 20x brightfield annotation files are generated appropriately. Run the below section. Wait for the \"20x brighfield acquisition done!\" message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch 20x acquisition\n",
    "switch_objective(config, core, '20x')\n",
    "switch_mod(config, core, 'bf')\n",
    "slide_name = acq_name\n",
    "pd_arr_r = pd.read_csv(os.path.join(save_path, acq_name_4x+'-z_pos.csv'))\n",
    "z_pos_4x = np.array(pd_arr_r)\n",
    "position_list_z = z_pos_4x\n",
    "position_list = generate_grid(config, mag='4x')\n",
    "position_list_xyz = np.concatenate((position_list, position_list_z.reshape((position_list.shape[0], position_list.shape[1], 1))), 2)\n",
    "position_lists_20x, annotation_names = annotations_positionlist(config, image_name=acq_name_4x, out_mag='20x')\n",
    "return_20x_list = []\n",
    "for idx, roi in enumerate(position_lists_20x):\n",
    "#     if idx <=7:\n",
    "#         return_20x_list.append(None)\n",
    "#         continue\n",
    "    current_acq_name = slide_name + '-20x-' + annotation_names[idx]\n",
    "    sampled_pos_xyz = resample_z_pos(config, mag='20x', xy_pos=roi, xyz_pos_list_4x=position_list_xyz)\n",
    "    if idx==0:\n",
    "        returns_20x = whole_slide_scan(config, core=core, save_path=save_path, acq_name=current_acq_name, mag='20x', position_list=sampled_pos_xyz, mda=False, estimate_background=True, focus_dive=True)\n",
    "        stitching(config, ij, save_path=save_path, acq_name=current_acq_name, mag='20x', mda=False, position_list=sampled_pos_xyz, flip_y=True, correction=True, background_image=returns_20x[0])\n",
    "        bg_img = returns_20x[0]\n",
    "    else:\n",
    "        returns_20x = whole_slide_scan(config, core=core, save_path=save_path, acq_name=current_acq_name, mag='20x', position_list=sampled_pos_xyz, mda=False, estimate_background=False, background_image=bg_img, focus_dive=True)\n",
    "        stitching(config, ij, save_path=save_path, acq_name=current_acq_name, mag='20x', mda=False, position_list=sampled_pos_xyz, flip_y=True, correction=False)\n",
    "    export_slide(mag='20x', remove_file=True)\n",
    "    return_20x_list.append(returns_20x[-1]) ### store focus map\n",
    "    np.save(os.path.join(save_path, slide_name +'-20x'+'-z_pos.npy'), return_20x_list, allow_pickle=True)\n",
    "    print('Object: {}/{}'.format(idx+1, len(position_lists_20x)))\n",
    "print('\\r, 20x brighfield acquisition done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SHG acquisition at 20x\n",
    "Make sure SHG annotation files are generated appropriately. Run the below section. Wait for the \"20x brighfield acquisition done!\" message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch shg acquisition use all map\n",
    "switch_objective(config, core, '20x')\n",
    "switch_mod(config, core, 'shg')\n",
    "save_path = 'data/acquisition'\n",
    "slide_name = acq_name\n",
    "position_lists_mp, annotation_mp = annotations_positionlist(config, image_name=acq_name_4x, out_mag='mp')\n",
    "position_lists_20x, annotation_names = annotations_positionlist(config, image_name=acq_name_4x, out_mag='20x')\n",
    "return_20x_list = np.load(os.path.join(save_path, slide_name+'-20x'+'-z_pos.npy'), allow_pickle=True).tolist()\n",
    "return_20x_list = np.vstack(return_20x_list)\n",
    "position_lists_20x =  np.vstack(position_lists_20x)\n",
    "map_xyz_20x = np.concatenate((position_lists_20x, return_20x_list.reshape((return_20x_list.shape[0], 1))), 1)\n",
    "for idx, roi in enumerate(position_lists_mp):\n",
    "#     if annotation_mp[idx] != annotation_names[idx]:\n",
    "#         print('\\n Unmatched annotation! \\n')\n",
    "    current_acq_name = slide_name + '-lsm-' + annotation_mp[idx]\n",
    "    sampled_pos_xyz_mp = resample_z_pos(config, mag='mp', xy_pos=roi, xyz_pos_list_20x=map_xyz_20x)\n",
    "    whole_slide_scan(config, core=core, save_path=save_path, acq_name=current_acq_name, position_list=sampled_pos_xyz_mp, mda=True, z_stack=True, sample_depth=24, z_step=6, estimate_background=False, focus_dive=False)\n",
    "    stitching(config, ij, save_path=save_path, acq_name=current_acq_name, mag='mp', mda=True, z_stack=True, position_list=sampled_pos_xyz_mp, flip_y=False, rotate=270, correction=None)\n",
    "    export_slide(mag='mp')\n",
    "print('\\r, SHG acquisition done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
